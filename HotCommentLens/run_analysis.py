"""
TF-IDFå…³é”®è¯æå– & äº‰è®®æ€§åˆ†æ - è¿è¡Œå…¥å£

==========================================================================
å¤§æ•°æ®åˆ†ææ–¹æ³•:
==========================================================================

1. TF-IDF (Term Frequency - Inverse Document Frequency)
   - TF: è¯åœ¨æ–‡æ¡£ä¸­çš„é¢‘ç‡
   - IDF: log(æ€»æ–‡æ¡£æ•° / åŒ…å«è¯¥è¯çš„æ–‡æ¡£æ•°)  
   - ç”¨äºè¯†åˆ«å„subredditçš„ç‰¹è‰²å…³é”®è¯

2. MapReduce æ¨¡å¼
   - Map: å¯¹æ¯æ¡è¯„è®ºåˆ†è¯ï¼Œè¾“å‡º(word, 1)
   - Reduce: æŒ‰ç»„èšåˆï¼Œç»Ÿè®¡è¯é¢‘
   
3. å‘é‡åŒ–æ“ä½œ
   - ä½¿ç”¨pandaså‘é‡æ“ä½œæ›¿ä»£å¾ªç¯
   - æå‡10-100å€æ€§èƒ½

4. åˆ†å±‚æŠ½æ ·
   - å¯¹æ¯”åˆ†ææ—¶å¹³è¡¡æ ·æœ¬

==========================================================================

ä½¿ç”¨æ–¹æ³•:
    python -m HotCommentLens.run_analysis
    python -m HotCommentLens.run_analysis --sample 100000
"""

import os
import sys
import time
import argparse
import pandas as pd
from datetime import datetime

from .config import Config
from .data_loader import RedditDataLoader
from .tfidf_controversy import TFIDFAnalyzer, ControversyAnalyzer, AnalysisVisualizer


def main():
    parser = argparse.ArgumentParser(
        description='TF-IDFå…³é”®è¯æå– & äº‰è®®æ€§åˆ†æ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
å¤§æ•°æ®åˆ†ææ–¹æ³•:
  1. TF-IDF: å…³é”®è¯æå–ï¼Œè¯†åˆ«ç¤¾åŒºç‰¹è‰²è¯æ±‡
  2. MapReduce: å¤§è§„æ¨¡è¯é¢‘ç»Ÿè®¡
  3. å‘é‡åŒ–: pandasé«˜æ•ˆè®¡ç®—
  4. åˆ†å±‚æŠ½æ ·: å¹³è¡¡å¯¹æ¯”åˆ†æ

ç¤ºä¾‹:
  python -m HotCommentLens.run_analysis
  python -m HotCommentLens.run_analysis --sample 100000
        """
    )
    parser.add_argument('--sample', type=int, default=None,
                       help='æŠ½æ ·æ•°é‡ (é»˜è®¤: å…¨éƒ¨æ•°æ®)')
    parser.add_argument('--data', type=str, default=None,
                       help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # è¾“å‡ºç›®å½•
    output_dir = args.output or os.path.join(Config.OUTPUT_DIR, "tfidf_controversy")
    os.makedirs(output_dir, exist_ok=True)
    
    print("\n" + "="*70)
    print("ğŸ”¬ Redditè¯„è®ºåˆ†æ: TF-IDFå…³é”®è¯ + äº‰è®®æ€§åˆ†æ")
    print("="*70)
    
    print("""
ğŸ“š ä½¿ç”¨çš„å¤§æ•°æ®æ–¹æ³•:
   1. TF-IDF (Term Frequency - Inverse Document Frequency)
      â†’ è¯†åˆ«å„subredditç‰¹è‰²å…³é”®è¯
   2. MapReduceæ¨¡å¼
      â†’ Map: æ–‡æ¡£åˆ†è¯  Reduce: è¯é¢‘èšåˆ
   3. å‘é‡åŒ–æ“ä½œ
      â†’ pandaså‘é‡è®¡ç®—ï¼Œæ›¿ä»£Pythonå¾ªç¯
   4. åˆ†å±‚æŠ½æ ·
      â†’ å¹³è¡¡äº‰è®®æ€§/éäº‰è®®æ€§æ ·æœ¬å¯¹æ¯”
""")
    
    # ==================== åŠ è½½æ•°æ® ====================
    print("="*50)
    print("ğŸ“‚ [æ•°æ®åŠ è½½]")
    print("="*50)
    
    start_time = time.time()
    
    loader = RedditDataLoader()
    if args.data:
        df = pd.read_csv(args.data)
    else:
        df = loader.load(num_comments=args.sample)
    
    # é€‚é…åˆ—å
    if 'text' in df.columns and 'body' not in df.columns:
        df['body'] = df['text']
    
    load_time = time.time() - start_time
    print(f"\nâœ… åŠ è½½å®Œæˆ: {len(df):,} æ¡è¯„è®º ({load_time:.2f}ç§’)")
    
    # æ•°æ®éªŒè¯
    required_cols = ['subreddit', 'body', 'controversiality', 'score']
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        print(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing}")
        sys.exit(1)
    
    # è¿‡æ»¤
    original_len = len(df)
    df = df.dropna(subset=['body', 'subreddit'])
    df = df[df['body'].str.len() >= 10]
    print(f"ğŸ“Š æœ‰æ•ˆè¯„è®º: {len(df):,} ({len(df)/original_len*100:.1f}%)")
    print(f"ğŸ“ Subreddits: {df['subreddit'].nunique()}")
    
    # ==================== ç¬¬ä¸€éƒ¨åˆ†: TF-IDF ====================
    print("\n" + "="*50)
    print("ğŸ“Œ ç¬¬ä¸€éƒ¨åˆ†: TF-IDFå…³é”®è¯æå–")
    print("="*50)
    
    tfidf_start = time.time()
    tfidf_analyzer = TFIDFAnalyzer()
    tfidf_results = tfidf_analyzer.compute_tfidf(df, text_column='body', group_column='subreddit')
    tfidf_time = time.time() - tfidf_start
    
    print(f"\nğŸ”‘ å„Subreddit TF-IDFå…³é”®è¯:")
    for sub in list(tfidf_results.keys())[:6]:
        keywords = tfidf_results[sub][:5]
        kw_str = ', '.join([w for w, _ in keywords])
        print(f"   r/{sub}: {kw_str}")
    
    # ==================== ç¬¬äºŒéƒ¨åˆ†: äº‰è®®æ€§åˆ†æ ====================
    print("\n" + "="*50)
    print("ğŸ“Œ ç¬¬äºŒéƒ¨åˆ†: äº‰è®®æ€§åˆ†æ")
    print("="*50)
    
    controversy_start = time.time()
    controversy_analyzer = ControversyAnalyzer()
    stats = controversy_analyzer.analyze(df, text_column='body')
    controversy_time = time.time() - controversy_start
    
    # ==================== å¯è§†åŒ– ====================
    print("\n" + "="*50)
    print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–")
    print("="*50)
    
    viz = AnalysisVisualizer(output_dir)
    viz.plot_tfidf_keywords(tfidf_results)
    viz.plot_controversy_stats(stats)
    viz.plot_keyword_comparison(stats.controversial_keywords, stats.non_controversial_keywords)
    
    # ==================== å¯¼å‡ºç»“æœ ====================
    print("\n" + "="*50)
    print("ğŸ’¾ å¯¼å‡ºç»“æœ")
    print("="*50)
    
    # TF-IDFç»“æœ
    tfidf_rows = []
    for sub, keywords in tfidf_results.items():
        for rank, (word, score) in enumerate(keywords, 1):
            tfidf_rows.append({
                'subreddit': sub,
                'rank': rank,
                'keyword': word,
                'tfidf_score': round(score, 6)
            })
    tfidf_df = pd.DataFrame(tfidf_rows)
    tfidf_df.to_csv(os.path.join(output_dir, 'tfidf_keywords.csv'),
                    index=False, encoding='utf-8-sig')
    try:
        tfidf_df.to_excel(os.path.join(output_dir, 'tfidf_keywords.xlsx'), index=False)
        print(f"   âœ… tfidf_keywords.csv/xlsx")
    except ImportError:
        print(f"   âœ… tfidf_keywords.csv")
    
    # äº‰è®®æ€§ç»Ÿè®¡
    stats_data = {
        'Metric': ['Total Comments', 'Controversial', 'Non-controversial',
                   'Controversy Rate (%)', 'Avg Length (Controversial)',
                   'Avg Length (Non-controversial)', 'Avg Score (Controversial)',
                   'Avg Score (Non-controversial)'],
        'Value': [stats.total_comments, stats.controversial_count,
                  stats.non_controversial_count, f"{stats.controversy_rate:.2f}",
                  f"{stats.avg_length_controversial:.1f}",
                  f"{stats.avg_length_non_controversial:.1f}",
                  f"{stats.avg_score_controversial:.2f}",
                  f"{stats.avg_score_non_controversial:.2f}"]
    }
    pd.DataFrame(stats_data).to_csv(
        os.path.join(output_dir, 'controversy_stats.csv'),
        index=False, encoding='utf-8-sig'
    )
    print(f"   âœ… controversy_stats.csv")
    
    # Subredditäº‰è®®ç‡
    sub_rates = pd.DataFrame([
        {'subreddit': sub, 'controversy_rate': rate}
        for sub, rate in stats.subreddit_controversy_rates.items()
    ]).sort_values('controversy_rate', ascending=False)
    sub_rates.to_csv(os.path.join(output_dir, 'subreddit_controversy_rates.csv'),
                     index=False, encoding='utf-8-sig')
    print(f"   âœ… subreddit_controversy_rates.csv")
    
    # å…³é”®è¯å¯¹æ¯”
    kw_rows = []
    for word, score in stats.controversial_keywords[:30]:
        kw_rows.append({'type': 'controversial', 'keyword': word, 'score': score})
    for word, score in stats.non_controversial_keywords[:30]:
        kw_rows.append({'type': 'non_controversial', 'keyword': word, 'score': score})
    pd.DataFrame(kw_rows).to_csv(
        os.path.join(output_dir, 'keyword_comparison.csv'),
        index=False, encoding='utf-8-sig'
    )
    print(f"   âœ… keyword_comparison.csv")
    
    # ==================== å®Œæˆ ====================
    total_time = time.time() - start_time
    
    print("\n" + "="*70)
    print("âœ… åˆ†æå®Œæˆ!")
    print("="*70)
    
    print(f"""
ğŸ“ è¾“å‡ºç›®å½•: {output_dir}
   - visualizations/
     - tfidf_keywords.png
     - controversy_analysis.png  
     - keyword_comparison.png
   - tfidf_keywords.csv/xlsx
   - controversy_stats.csv
   - subreddit_controversy_rates.csv
   - keyword_comparison.csv

â±ï¸  è€—æ—¶ç»Ÿè®¡:
   æ•°æ®åŠ è½½: {load_time:.2f}ç§’
   TF-IDFåˆ†æ: {tfidf_time:.2f}ç§’
   äº‰è®®æ€§åˆ†æ: {controversy_time:.2f}ç§’
   æ€»è®¡: {total_time:.2f}ç§’

ğŸ“š ä½¿ç”¨çš„å¤§æ•°æ®æ–¹æ³•:
   âœ“ TF-IDF - å…³é”®è¯æå–
   âœ“ MapReduce - è¯é¢‘ç»Ÿè®¡
   âœ“ å‘é‡åŒ–æ“ä½œ - é«˜æ•ˆè®¡ç®—
   âœ“ åˆ†å±‚æŠ½æ · - å¹³è¡¡å¯¹æ¯”
""")


if __name__ == '__main__':
    main()
